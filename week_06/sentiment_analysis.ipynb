{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using data processing techniques and NLP to infer a _sentiment_ of a piece of text. We will only look at _polarity_ today — positive vs. negative opinion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use cases for sentiment analysis:\n",
    "* Product/app reviews\n",
    "* Public opinion tracking\n",
    "* Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems with sentiment analysis / why is sentiment analysis hard:\n",
    "* Sentiment isn't a binary\n",
    "* Irony / sarcasm / tone\n",
    "* Emojis\n",
    "* `Plot was ok, dialogue was a bit boring, but the acting was great!`\n",
    "* `It wasn't an uninteresting movie.`, `I'm not saying it was an uninteresting movie.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB movie reviews dataset: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "* 25000 positive & 25000 negative reviews\n",
    "* 50/50 training/test split\n",
    "* 7 stars or more -> positive review\n",
    "* 4 starts or fewer -> negative review\n",
    "* at most 30 reviews per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(dataset):\n",
    "    corpus = []\n",
    "    labels = []\n",
    "    for rev in ['pos', 'neg']:\n",
    "        for file in os.listdir('./aclImdb/' + dataset + '/'+ rev + '/'):\n",
    "            file_path = './aclImdb/' + dataset + '/'+ rev + '/' + file\n",
    "            with open(file_path, 'r') as f:\n",
    "                corpus.append(f.read())\n",
    "                if rev == 'pos':\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "    return corpus, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train, y_train = read_corpus('train')\n",
    "corpus_test, y_test = read_corpus('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approaches\n",
    "\n",
    "1. rule-based (unsupervised)\n",
    "2. vectorization / ML model (supervised)\n",
    "3. deep learning / RNN / LSTM (supervised) — won't cover this today, you'll hear more about deep learning in Week 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.a. Lexicon-based method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with two lexicons of words associated with positive and negative sentiments.\n",
    "\n",
    "`positive-words.txt`: https://gist.github.com/mkulakowski2/4289437\n",
    "\n",
    "`negative-words.txt`: https://gist.github.com/mkulakowski2/4289441"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's imagine you have an unlabeled dataset of movie reviews. How would you use these lists of positive and negative words to infer the sentiment of the reviews?\n",
    "* count positive and negative words, assign the label of the larger count\n",
    "* the last word in the review that's in either of the lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_words(sentiment):\n",
    "    f = open(f'posneg/{sentiment}-words.txt', mode='r')\n",
    "    result = f.readlines()\n",
    "    f.close()\n",
    "    result = [line.strip('\\n') for line in result if not line.startswith(';') and len(line)>1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_sentiment(corpus):\n",
    "    y_pred = []\n",
    "    for text in corpus:\n",
    "        n_pos = len([w for w in positive_words if w in text])/len(positive_words)\n",
    "        n_neg = len([w for w in negative_words if w in text])/len(negative_words)\n",
    "        if n_pos > n_neg:\n",
    "            y_pred.append(1)\n",
    "        elif n_pos < n_neg:\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(np.random.choice([0, 1]))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = read_words('positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = read_words('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lexicon = determine_sentiment(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6664"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_lexicon, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.b. VADER Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[VADER](https://github.com/cjhutto/vaderSentiment) (Valence Aware Dictionary and sEntiment Reasoner) is a rule-based model for sentiment analysis that takes into account polarity (positive vs. negative) but also intensity of a sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in /Users/marija/anaconda3/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /Users/marija/anaconda3/lib/python3.8/site-packages (from vaderSentiment) (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/marija/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/marija/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/marija/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/marija/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You task is to implement sentiment analysis using VADER, following the README file here: \n",
    "\n",
    "https://github.com/cjhutto/vaderSentiment#code-examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each review in your test corpus, determine the sentiment (positive or negative), and compare that with the labels for your test set to determine accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_vader = []\n",
    "for text in corpus_test:\n",
    "    compound_score = analyzer.polarity_scores(text)['compound']\n",
    "    if compound_score >= 0.05:\n",
    "        y_pred_vader.append(1)\n",
    "    elif compound_score <= -0.05:\n",
    "        y_pred_vader.append(0)\n",
    "    else:\n",
    "        y_pred_vader.append(np.random.choice([0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69716"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_vader, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Vectorization / ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This follows the approach you've seen in Week 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(CountVectorizer(stop_words='english', ngram_range=(1, 2)),\n",
    "                         TfidfTransformer(),\n",
    "                         LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
       "                ('tfidftransformer', TfidfTransformer()),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(corpus_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87344"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pipeline['logisticregression'].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = pipeline['countvectorizer'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bad', 'worst', 'awful', 'waste', 'boring', 'poor', 'terrible', 'worse', 'script', 'minutes', 'stupid', 'horrible', 'just', 'plot', 'supposed', 'dull', 'poorly', 'instead', 'waste time', 'money')\n"
     ]
    }
   ],
   "source": [
    "print(operator.itemgetter(*np.argsort(weights))(feature_names)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fantastic', 'definitely', 'enjoy', 'superb', 'highly', 'life', 'brilliant', 'today', 'enjoyed', 'beautiful', 'favorite', 'loved', 'fun', 'amazing', 'perfect', 'wonderful', 'love', 'best', 'excellent', 'great')\n"
     ]
    }
   ],
   "source": [
    "print(operator.itemgetter(*np.argsort(weights))(feature_names)[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BONUS: `operator.itemgetter()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [i for i in range(3, 15)]\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`operator.itemgetter()` returns the element(s) corresponding to the index (or the list of indices) passed to it as arguments. The order of returned elements is the same as the order of corresponding indices passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 4, 7)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operator.itemgetter(6, 1, 4)(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BONUS: `*args`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`*args` is used to pass variable number of arguments to a function, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_all(*args):\n",
    "    s = 0\n",
    "    for i in args:\n",
    "        s = s+i\n",
    "    return sum_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s(3, 6, 9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
